{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP on MINST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Updating METADATA...\n",
      "INFO: Computing changes...\n",
      "INFO: No packages to install, update or remove\n",
      "INFO: Nothing to be done\n"
     ]
    }
   ],
   "source": [
    "Pkg.update()\n",
    "Pkg.add(\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],\n",
       "\n",
       "[7.0,2.0,1.0,0.0,4.0,1.0,4.0,9.0,5.0,9.0  …  7.0,8.0,9.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MNIST\n",
    "features = trainfeatures(1)\n",
    "label = trainlabel(1)\n",
    "\n",
    "trainX, trainY = traindata()\n",
    "testX, testY = testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstract Layer\n",
    "abstract Nonlinearity <: Layer\n",
    "abstract LossCriteria <: Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCLayer([0.454393 0.762753 … 0.342354 0.697576; 0.431816 0.796653 … 0.756396 0.63993; … ; 0.128833 0.101582 … 0.408479 0.951413; 0.216083 0.999274 … 0.306752 0.483132],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Fully Connected layers\n",
    "type FCLayer <: Layer\n",
    "    W           :: Array{Float64}\n",
    "    last_input  :: Array{Float64}\n",
    "    last_output :: Array{Float64}\n",
    "    last_loss   :: Array{Float64}\n",
    "\n",
    "    function FCLayer(i, o)\n",
    "        return new(rand(o,i), zeros(i), zeros(o), zeros(o))\n",
    "    end\n",
    "end\n",
    "\n",
    "function forward(l::FCLayer, x::Array{Float64,2})\n",
    "    @assert size(x) == (size(l.W)[2],1)\n",
    "    l.last_input  = x\n",
    "    l.last_output = l.W * x # matrix multiplication\n",
    "    l.last_output\n",
    "end\n",
    "\n",
    "function backward(l::FCLayer, loss::Array{Float64,1})\n",
    "    @assert size(loss) == (size(l.W)[1],1)\n",
    "    l.last_loss = loss\n",
    "    l.W'*loss \n",
    "end\n",
    "\n",
    "function gradient(l::FCLayer, loss::Array{Float64,1})\n",
    "    @assert size(loss) == (size(l.W)[1],1)\n",
    "    l.last_loss = loss\n",
    "    l.W .* loss\n",
    "end\n",
    "FCLayer(10,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLu(1.0,Float64[],Float64[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the ReLu layers\n",
    "type ReLu <: Nonlinearity\n",
    "    alpha       :: Float64\n",
    "    last_input  :: Array{Float64}\n",
    "    last_output :: Array{Float64}\n",
    "    last_loss   :: Array{Float64}\n",
    "    function ReLu(alpha::Float64 = 1.0)\n",
    "        @assert alpha >= 0.\n",
    "        return new(alpha, Float64[], Float64[], Float64[])\n",
    "    end\n",
    "end\n",
    "\n",
    "function forward(l::ReLu, x::Array{Float64})\n",
    "    l.last_input  = x\n",
    "    l.last_output = map(y -> max(0., y*l.alpha), x)\n",
    "    l.last_output\n",
    "end\n",
    "\n",
    "function backward(l::ReLu, loss::Array{Float64})\n",
    "    @assert size(l.last_input) == size(loss)\n",
    "    l.last_loss = loss\n",
    "    map(idx -> l.last_input[idx]>=0 ? l.last_input[idx]*l.alpha*loss[idx] : 0., indices(x))\n",
    "end\n",
    "\n",
    "ReLu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type CrossEntropyLoss <: LossCriteria\n",
    "    last_loss  :: Array{Float64}\n",
    "    last_input :: Array{Float64}\n",
    "end    \n",
    "\n",
    "function forward(l::CrossEntropyLoss, y::Array{Float64}, label::Array{Int32})\n",
    "    \"\"\"\n",
    "    [label]  label[i] == 1 iff the data is classified to class i\n",
    "    [y]      final input to the loss layer\n",
    "    \"\"\"\n",
    "    @assert min(label) >= 0 && sum(label) == 1\n",
    "    @assert size(y) == size(label)\n",
    "    sum(-log(e .^ y ./ sum(e .^ y)) .* label)\n",
    "end\n",
    "\n",
    "function backward(l::CrossEntropyLoss, x::Array{Float64}, label::Array{Int32})\n",
    "    \"\"\"\n",
    "    [label]  label[i] == 1 iff the data is classified to class i\n",
    "    [y]      final input to the loss layer\n",
    "    \"\"\"\n",
    "    @assert min(label) >= 0 && sum(label) == 1\n",
    "    @assert size(x) == size(loss)\n",
    "    y = e.^x / sum(e.^x)\n",
    "    c = filter(i -> label[i] == 1, indices(label))[1]\n",
    "    map(j -> c==j ? y[c]*(1-y[c]) : -y[c]*y[j], indices(x))\n",
    "end\n",
    "CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 4 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract NN\n",
    "type SequentialNet <: NN\n",
    "    layers :: Array{Layer}\n",
    "    lossfn :: LossCriteria\n",
    "    function SequentialNet(layers::Array{Layer}, lossfn::LossCriteria)\n",
    "        return new(layers, lossfn, Array{Float64}[], Array{Float64}[])\n",
    "    end\n",
    "end\n",
    "\n",
    "function forward(net::SequentialNet, x::Array{Float64}, label::Array)\n",
    "    local inp = x\n",
    "    for i = 1:length(NN)\n",
    "        inp = forward(net.layers[i], inp)\n",
    "    end\n",
    "    forward(net.lossfn, inp, label)\n",
    "end\n",
    "\n",
    "function backward(net::SequentialNet, label::Array)\n",
    "    @assert size(dldy) == size(net.inputs[end])\n",
    "    dldy = backward(net.lossfn, net.inputs[end], label)\n",
    "    for i = length(net.layers):-1:1\n",
    "        net.losses[i] = backward(net.layers[i], dldy)\n",
    "    end\n",
    "    dldy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialNet(Layer[FCLayer([0.386414 0.190032 … 0.242685 0.218318; 0.887087 0.351738 … 0.733746 0.762715; … ; 0.51793 0.394179 … 0.733619 0.129296; 0.566743 0.291666 … 0.340952 0.27762],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  …  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  …  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  …  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),ReLu(1.0,Float64[],Float64[]),FCLayer([0.940246 0.343635 … 0.142609 0.459007; 0.599952 0.583976 … 0.503514 0.145608; … ; 0.917356 0.247246 … 0.41323 0.660878; 0.782501 0.234676 … 0.87153 0.428659],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  …  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  …  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  …  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),ReLu(1.0,Float64[],Float64[]),FCLayer([0.424201 0.0713058 … 0.671137 0.00431872; 0.66011 0.355768 … 0.404742 0.127599; … ; 0.785753 0.0357303 … 0.445131 0.102482; 0.691326 0.857254 … 0.198561 0.600286],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  …  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])],CrossEntropyLoss(),Array{Float64,N}[],Array{Float64,N}[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [\n",
    "    FCLayer(784, 196),\n",
    "    ReLu(),\n",
    "    FCLayer(196, 49),\n",
    "    ReLu(),\n",
    "    FCLayer(49, 10)\n",
    "]\n",
    "criteria = CrossEntropyLoss()\n",
    "net = SequentialNet(layers, criteria)\n",
    "\n",
    "function sgd(net::SequentialNet, batch_X, batch_Y)\n",
    "    local gradients \n",
    "    for b = 1:length(batch_X)\n",
    "        \n",
    "    end\n",
    "end\n",
    "\n",
    "function trainer(net::SequentialNet, X, Y)\n",
    "    for epo = 1:100\n",
    "        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,784),(10000,784))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = trainX'\n",
    "testX = testX'\n",
    "size(trainX'), size(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
